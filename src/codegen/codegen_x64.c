/* ========================================
   SUB Language - x86-64 Native Code Generator
   Implementation
   File: codegen_x64.c
   ======================================== */

#define _GNU_SOURCE
#include "codegen_x64.h"
#include "windows_compat.h"
#include <stdlib.h>
#include <string.h>
#include <stdarg.h>

/* Register names for AT&T syntax (GCC/Clang) */
static const char* register_names_64[] = {
    "rax", "rbx", "rcx", "rdx", "rsi", "rdi", "rbp", "rsp",
    "r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15"
};

static const char* register_names_32[] = {
    "eax", "ebx", "ecx", "edx", "esi", "edi", "ebp", "esp",
    "r8d", "r9d", "r10d", "r11d", "r12d", "r13d", "r14d", "r15d"
};

/* Create code generation context */
X64Context* x64_context_create(FILE *output) {
    X64Context *ctx = calloc(1, sizeof(X64Context));
    ctx->output = output;
    ctx->label_counter = 0;
    ctx->string_counter = 0;
    ctx->stack_offset = 0;
    
    // Mark special registers as in use
    ctx->reg_in_use[X64_REG_RSP] = true;
    ctx->reg_in_use[X64_REG_RBP] = true;
    
    return ctx;
}

void x64_context_free(X64Context *ctx) {
    free(ctx);
}

/* Get register name */
const char* x64_register_name(X64Register reg, bool is_64bit) {
    if (reg >= X64_REG_COUNT) return "INVALID";
    return is_64bit ? register_names_64[reg] : register_names_32[reg];
}

/* Allocate a free register */
X64Register x64_alloc_register(X64Context *ctx) {
    // Prefer caller-saved registers first
    X64Register priority[] = {X64_REG_RAX, X64_REG_RCX, X64_REG_RDX, X64_REG_RSI, X64_REG_RDI, 
                               X64_REG_R8, X64_REG_R9, X64_REG_R10, X64_REG_R11};
    
    for (int i = 0; i < 9; i++) {
        if (!ctx->reg_in_use[priority[i]]) {
            ctx->reg_in_use[priority[i]] = true;
            return priority[i];
        }
    }
    
    // Fall back to callee-saved registers
    for (int i = X64_REG_RBX; i < X64_REG_COUNT; i++) {
        if (!ctx->reg_in_use[i]) {
            ctx->reg_in_use[i] = true;
            return i;
        }
    }
    
    return X64_REG_RAX; // Fallback
}

void x64_free_register(X64Context *ctx, X64Register reg) {
    if (reg != X64_REG_RSP && reg != X64_REG_RBP) {
        ctx->reg_in_use[reg] = false;
    }
}

int x64_generate_label(X64Context *ctx) {
    return ctx->label_counter++;
}

/* Emit assembly code */
void x64_emit(X64Context *ctx, const char *format, ...) {
    va_list args;
    va_start(args, format);
    fprintf(ctx->output, "    ");
    vfprintf(ctx->output, format, args);
    fprintf(ctx->output, "\n");
    va_end(args);
}

void x64_emit_comment(X64Context *ctx, const char *comment) {
    fprintf(ctx->output, "    # %s\n", comment);
}

void x64_emit_label(X64Context *ctx, const char *label) {
    fprintf(ctx->output, "%s:\n", label);
}

/* Generate program prologue */
static void x64_generate_prologue(X64Context *ctx) {
    fprintf(ctx->output, "# Generated by SUB Native Compiler\n");
    fprintf(ctx->output, "# Architecture: x86-64\n\n");
    
    fprintf(ctx->output, ".section .rodata\n");
    fprintf(ctx->output, ".LC0:\n");
    fprintf(ctx->output, "    .string \"%%ld\\n\"\n");
    fprintf(ctx->output, ".section .data\n");
    fprintf(ctx->output, ".section .text\n");
    fprintf(ctx->output, ".global main\n\n");
}

/* Generate function prologue */
static void x64_generate_function_prologue(X64Context *ctx, IRFunction *func) {
    x64_emit_label(ctx, func->name);
    x64_emit_comment(ctx, "Function prologue");
    x64_emit(ctx, "pushq %%rbp");
    x64_emit(ctx, "movq %%rsp, %%rbp");
    
    // Allocate stack space for parameters and locals
    int total_stack = func->local_count * 8 + func->param_count * 8;
    if (total_stack > 0) {
        total_stack = (total_stack + 15) & ~15; // Align to 16 bytes
        x64_emit(ctx, "subq $%d, %%rsp", total_stack);
    }
    
    // Save parameters to stack (now below the allocated area)
    for (int i = 0; i < func->param_count; i++) {
        const char *reg;
        switch(i) {
            case 0: reg = "rdi"; break;
            case 1: reg = "rsi"; break;
            case 2: reg = "rdx"; break;
            case 3: reg = "rcx"; break;
            case 4: reg = "r8"; break;
            case 5: reg = "r9"; break;
            default: reg = "rdi"; break;
        }
        // Parameters at: [rbp - (param_index + 1) * 8]
        int offset = (i + 1) * 8;
        x64_emit(ctx, "movq %%%s, -%d(%%rbp)", reg, offset);
    }
}

/* Generate function epilogue */
static void x64_generate_function_epilogue(X64Context *ctx, IRFunction *func) {
    x64_emit_comment(ctx, "Function epilogue");
    
    // Create unique return label (e.g., "main_return:" instead of "main:")
    char return_label[256];
    snprintf(return_label, sizeof(return_label), "%s_return", func->name);
    x64_emit_label(ctx, return_label);
    
    x64_emit(ctx, "movq %%rbp, %%rsp");
    x64_emit(ctx, "popq %%rbp");
    x64_emit(ctx, "ret\n");
}

/* Generate instruction */
void x64_generate_instruction(X64Context *ctx, IRInstruction *instr) {
    if (!instr) return;
    
    switch (instr->opcode) {
        case IR_CONST_INT:
            if (instr->dest) {
                x64_emit(ctx, "movq $%ld, %%rax", instr->src1->data.int_val);
            }
            break;
            
        case IR_PUSH:
             x64_emit(ctx, "pushq %%rax");
             break;

        case IR_ADD:
            x64_emit_comment(ctx, "ADD operation");
            x64_emit(ctx, "popq %%rbx"); // Pop left operand
            x64_emit(ctx, "addq %%rbx, %%rax");
            break;
            
        case IR_SUB:
            x64_emit_comment(ctx, "SUB operation");
            x64_emit(ctx, "movq %%rax, %%rbx"); // Right operand -> RBX
            x64_emit(ctx, "popq %%rax");        // Left operand -> RAX
            x64_emit(ctx, "subq %%rbx, %%rax"); // Left - Right
            break;
            
        case IR_MUL:
            x64_emit_comment(ctx, "MUL operation");
            x64_emit(ctx, "popq %%rbx");
            x64_emit(ctx, "imulq %%rbx, %%rax");
            break;
            
        case IR_DIV:
            x64_emit_comment(ctx, "DIV operation");
            x64_emit(ctx, "movq %%rax, %%rbx"); // Right -> RBX (divisor)
            x64_emit(ctx, "popq %%rax");        // Left -> RAX (dividend)
            x64_emit(ctx, "cqto");
            x64_emit(ctx, "idivq %%rbx");
            break;
            
        case IR_RETURN:
            if (instr->src1) {
                if (instr->src1->kind == IR_VAL_CONST) {
                     x64_emit(ctx, "movq $%ld, %%rax", instr->src1->data.int_val);
                } else if (instr->src1->kind == IR_VAL_REG) {
                     // If it's a register, we likely need to map it to RAX.
                     // But we don't know WHICH physical register the virtual register is in!
                     // The naive stack-based codegen assumes regs are popped?
                     // Wait, our IR uses virtual regs.
                     // IR_ADD pops to RAX.
                     // If IR_RETURN src is implicit (last result), it's in RAX.
                     // But if src1 is EXPLICIT register from `ir.c` (reg_count - 1),
                     // we need to know where `reg_count-1` is.
                     
                     // In stack-machine mode (current codegen):
                     // Operations leave result in RAX (and/or stack).
                     // If ir.c sets src1 to "last register", it implies "current accumulator".
                     // So we implicitly satisfy it?
                     // BUT, if we have `x = 1; return x`:
                     // LOAD 0 -> RAX=1.
                     // RETURN (src=reg for x).
                     // We need to move value of reg x to RAX.
                     
                     // How does codegen access generic registers?
                     // `IR_LOAD` emits `movq -off(%rbp), %rax`.
                     // Does `IR_RETURN` need to generate a load?
                     // Yes! If src1 is a register that needs to be returned.
                     
                     // But `ir.c` logic for `AST_RETURN_STMT` sets src1 to `func->reg_count - 1`.
                     // `reg_count-1` is a virtual temporary.
                     // Where is it stored?
                     // `IR_ADD` result: `addq %rbx, %rax` -> result in RAX. DOES NOT STORE to stack/reg map.
                     // Unless there is a store?
                     // `ir.c` `IR_ADD` dest is `reg_count++`.
                     // Logic: `bin_op->dest = ir_value_create_reg(...)`.
                     // But `codegen` ignores `dest` for ADD! It keeps result in RAX.
                     
                     // CRITICAL: The codegen assumes RAX holds the result of the last operation.
                     // If `IR_RETURN` is generating `mov...` it clobbers RAX!
                     // If src1 is a CONST, `mov $val, %rax` is correct.
                     // If src1 is a REG, checking if it is the "current" reg (implicit in RAX).
                     // If `ir.c` guarantees src1 is the result of the previous instruction...
                     // Then it's already in RAX.
                     // So we do NOTHING.
                }
            }
            x64_emit(ctx, "jmp %s_return", instr->comment ? instr->comment : "main");
            break;

        case IR_ALLOC:
            x64_emit_comment(ctx, "Alloc variable (noop, stack reserved)");
            break;
            
        case IR_STORE:
            x64_emit_comment(ctx, "Store variable");
            // dest is the variable register (index), src implicitly in RAX from previous expr
            // Stack offset = (reg_num + 1) * 8
            if (instr->dest) {
                int offset = (instr->dest->data.reg_num + 1) * 8;
                x64_emit(ctx, "movq %%rax, -%d(%%rbp)", offset);
            }
            break;
            
        case IR_LOAD:
            x64_emit_comment(ctx, "Load variable");
            // src1 is the variable register
            if (instr->src1) {
                int offset = (instr->src1->data.reg_num + 1) * 8;
                x64_emit(ctx, "movq -%d(%%rbp), %%rax", offset);
            }
            break;
            
        case IR_PRINT:
            x64_emit_comment(ctx, "Print integer");
            // Assuming the value to print is in RAX (from previous instruction)
            x64_emit(ctx, "movq %%rax, %%rsi"); // 2nd argument: value to print
            x64_emit(ctx, "leaq .LC0(%%rip), %%rdi"); // 1st argument: format string
            x64_emit(ctx, "xorq %%rax, %%rax"); // Clear RAX (no vector args)
            x64_emit(ctx, "call printf@PLT");
            break;
            
        case IR_JUMP_IF_NOT:
            x64_emit_comment(ctx, "Jump if false (0)");
            x64_emit(ctx, "cmpq $0, %%rax");
            if (instr->dest && instr->dest->data.label) {
                x64_emit(ctx, "je %s", instr->dest->data.label);
            }
            break;

        case IR_EQ:
        case IR_NE:
        case IR_LT:
        case IR_LE:
        case IR_GT:
        case IR_GE:
            x64_emit_comment(ctx, "Comparison");
            x64_emit(ctx, "movq %%rax, %%rbx"); // Right -> RBX
            x64_emit(ctx, "popq %%rax");        // Left -> RAX
            x64_emit(ctx, "cmpq %%rbx, %%rax"); // Compare Left (RAX) vs Right (RBX)
            x64_emit(ctx, "movq $0, %%rax");    // Default false
            const char *set_instr = "sete"; // Default EQ
            switch(instr->opcode) {
                case IR_EQ: set_instr = "sete"; break;
                case IR_NE: set_instr = "setne"; break;
                case IR_LT: set_instr = "setl"; break;
                case IR_LE: set_instr = "setle"; break;
                case IR_GT: set_instr = "setg"; break;
                case IR_GE: set_instr = "setge"; break;
                default: break;
            }
            x64_emit(ctx, "%s %%al", set_instr);
            break;
            
        case IR_LABEL:
            if (instr->dest && instr->dest->data.label) {
                x64_emit_label(ctx, instr->dest->data.label);
            }
            break;
            
        case IR_JUMP:
            if (instr->dest && instr->dest->data.label) {
                x64_emit(ctx, "jmp %s", instr->dest->data.label);
            }
            break;
            
        case IR_CALL:
            x64_emit_comment(ctx, "Function call");
            
            int arg_count = 0;
            if (instr->src1 && instr->src1->type == IR_TYPE_INT) {
                arg_count = (int)instr->src1->data.int_val;
            }
            
            // Arguments were pushed in order: arg0, arg1, ... argN
            // Stack top is argN.
            // ABI expects: RDI, RSI, RDX, RCX, R8, R9.
            // We must POP in REVERSE ABI order: R9, R8, RCX, RDX, RSI, RDI.
            
            // Handle up to 6 arguments for now
            // Note: We only pop if count >= N, but we must do it in specific order.
            // Actually, we simply pop 'arg_count' times.
            // If count is 1: Stack: [arg0]. Pop -> RDI.
            // If count is 2: Stack: [arg0, arg1]. Pop -> RSI, Pop -> RDI.
            // Wait, PUSH order in ir.c loop:
            // for i=0..count: push child[i]. 
            // So stack is: arg0 (bottom), arg1, arg2 (top).
            // POP gives arg2 (RDX).
            // POP gives arg1 (RSI).
            // POP gives arg0 (RDI).
            // So we just need to determine WHICH register correspond to the CURRENT pop.
            // loop k from count-1 down to 0:
            //   reg = abi[k]
            //   pop reg
            
            const char *abi_regs[] = { "rdi", "rsi", "rdx", "rcx", "r8", "r9" };
            for (int k = arg_count - 1; k >= 0; k--) {
                if (k < 6) {
                    x64_emit(ctx, "popq %%%s", abi_regs[k]);
                } else {
                    // TODO: Stack arguments for > 6 args
                     x64_emit_comment(ctx, "Arg > 6 ignored for now");
                     x64_emit(ctx, "addq $8, %%rsp"); // wrapper pop
                }
            }
            
            // Align stack if needed (System V requires 16-byte alignment before call)
            // Current simplistic approach aligns in prologue.
            
            x64_emit(ctx, "xorq %%rax, %%rax"); // Variadic args (AL=0)
            if (instr->dest && instr->dest->data.label) {
                x64_emit(ctx, "call %s", instr->dest->data.label);
            }
            break;
            
        default:
            x64_emit_comment(ctx, "Unimplemented opcode");
            break;
    }
}

/* Generate function */
void x64_generate_function(X64Context *ctx, IRFunction *func) {
    if (!func) return;
    
    x64_generate_function_prologue(ctx, func);
    
    // Generate instructions
    IRInstruction *instr = func->instructions;
    while (instr) {
        x64_generate_instruction(ctx, instr);
        instr = instr->next;
    }
    
    x64_generate_function_epilogue(ctx, func);
}

/* Generate complete program */
void x64_generate_program(X64Context *ctx, IRModule *module) {
    if (!module) return;
    
    x64_generate_prologue(ctx);
    
    // Generate all functions
    IRFunction *func = module->functions;
    while (func) {
        x64_generate_function(ctx, func);
        func = func->next;
    }
    
    // Add exit code
    fprintf(ctx->output, "\n# Exit\n");
    fprintf(ctx->output, ".section .note.GNU-stack,\"\",@progbits\n");
}
